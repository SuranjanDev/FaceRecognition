{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='green'>Author: Suranjan Jena</font>\n",
    "#### <font color='green'>Date: August 25, 2016</font>\n",
    "# Face Recognition using neural networks :) \n",
    "\n",
    "\n",
    "# <font color='red'> Step 1: Face Detection</font>\n",
    "### This is done by using Haar Cascades.\n",
    "### It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images.\n",
    "### It takes an image and applies about 6000 features to check if it is a face or not!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Import the required libraries\n",
    "#\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols=50\n",
    "rows=50\n",
    "\n",
    "def detectFace(path):\n",
    "    img = cv2.imread(path)\n",
    "    cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    rects = cascade.detectMultiScale(gray, 1.3, 4, cv2.cv.CV_HAAR_SCALE_IMAGE, (20,20))\n",
    "    if len(rects) == 0:\n",
    "        return [], img\n",
    "    rects[:, 2:] += rects[:, :2]\n",
    "    return rects, img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"in.jpg\"style=\"float: left; width: 20%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"out.jpg\"style=\"float: left; width: 20%; margin-right: 1%; margin-bottom: 0.5em;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> Step 2: Extract the face and crop it to the required dimension</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cropFace(rects, img):\n",
    "    crop_img=img[rects[0][1]:rects[0][3],rects[0][0]:rects[0][2]]\n",
    "    gray=cv2.cvtColor(crop_img,cv2.COLOR_BGR2GRAY)    \n",
    "    gray_resized=cv2.resize(gray,(cols,rows))\n",
    "    cv2.imwrite('grayCropped.png',gray_resized)\n",
    "    imgArr=np.array(gray_resized)\n",
    "    return imgArr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Step 3: Feature Extraction.</font>\n",
    "### For feature extraction PCA was used.\n",
    "### PCA is based on the fact that some dimensional variation in a data set is more important than others.\n",
    "### PCA finds out the direction where the data is most spread out.\n",
    "<img src=\"pca.png\">\n",
    "\n",
    "\n",
    "\n",
    "### For our purpose we are just focusing on the first 49 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Pca(imgArr):\n",
    "    X=np.array(imgArr)\n",
    "    pca=PCA(n_components=49)\n",
    "    pca.fit(X).transform(X)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> Step 4: Prepare the training and the testing data set.</font>\n",
    "### For the training set I have 2145 images out of which 1001 images are my selfies, and the rest belongs to my friends "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileX=open(\"Train_inpImgX.txt\",\"w\")\n",
    "fileY=open(\"Train_inpImgY.txt\",\"w\")\n",
    "n=0\n",
    "for i in range(1,2145):\n",
    "    rects, img = detectFace(\"TrainPics/sample (\"+str(i)+\").jpg\")\n",
    "    if len(rects):        \n",
    "        mod_imgArr=cropFace(rects, img)\n",
    "        reducedDim=Pca(mod_imgArr)\n",
    "        fileX.writelines( \"%s \" % item for item in reducedDim.explained_variance_ratio_)\n",
    "        fileX.write(\"\\n\")\n",
    "        \n",
    "        if(i<1002):\n",
    "            fileY.writelines(\"%s\\n\"%str(1))\n",
    "        else:\n",
    "            fileY.writelines(\"%s\\n\"%str(0))\n",
    "            \n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        n=n+1\n",
    "fileX.close()\n",
    "fileY.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The number of features we have per image is now 49. So now all the 49 eigenvalues for all the 1957 images are stored onto a text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Step 5: Train and test using Neural networks.</font>\n",
    "<img src=\"nn.jpeg\">\n",
    "### Our network has 3 layers.\n",
    "### The input layer has 49 nodes, hidden layer has 15 nodes and the output layer has 2 nodes.\n",
    "<img src=\"tanh.gif\">\n",
    "<img src=\"tanh2.png\">\n",
    "### The output layer uses a Softmax function because it converts raw scores into probabilities. \n",
    "<img src=\"softmax.png\">\n",
    "### A common choice of the loss function for Softmax function is the cross-entropy loss\n",
    "<img src=\"error.png\">\n",
    "### Apply the back propagation formula\n",
    "<img src=\"derv.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    # Initialize the network \n",
    "    def __init__(self):\n",
    "        # number of input layer nodes\n",
    "        self.inputNodes = 49\n",
    "        # number of hidden layer nodes\n",
    "        self.hiddenNodes = 15\n",
    "        # number of output layer nodes\n",
    "        self.outputNodes = 2\n",
    "        # gradient descent stepsize \n",
    "        self.eta = 0.001\n",
    "        # number of iterations of the gradient descent each time it is called\n",
    "        self.iterations = 50000\n",
    "        # Initialize the parameters to random values\n",
    "        np.random.seed(0)\n",
    "        self.W1 = np.random.randn(self.inputNodes, self.hiddenNodes) / np.sqrt(self.inputNodes)\n",
    "        self.b1 = np.zeros((1, self.hiddenNodes))\n",
    "        self.W2 = np.random.randn(self.hiddenNodes, self.outputNodes) / np.sqrt(self.hiddenNodes)\n",
    "        self.b2 = np.zeros((1, self.outputNodes))\n",
    "        \n",
    "    # batch gradient descent for minimizing the error\n",
    "    def gradient_descent(self, X, y):\n",
    "        # sample size\n",
    "        N = len(X)\n",
    "        for i in range(self.iterations):\n",
    "            # forward propagation\n",
    "            s1 = X.dot(self.W1) + self.b1\n",
    "            a1 = np.tanh(s1)\n",
    "            s2 = a1.dot(self.W2) + self.b2\n",
    "            #activation fun for output is softmax\n",
    "            a2 = np.exp(s2) / np.sum(np.exp(s2), axis=1, keepdims=True)\n",
    "            # backpropagating the error\n",
    "            delta3 = a2\n",
    "            delta3[range(N), y.astype(int)] -= 1\n",
    "            dLW2 = (a1.T).dot(delta3)\n",
    "            dLb2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "            delta2 = delta3.dot(self.W2.T) * (1 - np.power(a1, 2))\n",
    "            dLW1 = np.dot(X.T, delta2)\n",
    "            dLb1 = np.sum(delta2, axis=0)\n",
    "            # update the weights\n",
    "            self.W1 = self.W1-self.eta * dLW1\n",
    "            self.b1 = self.b1-self.eta * dLb1\n",
    "            self.W2 = self.W2-self.eta * dLW2\n",
    "            self.b2 = self.b2-self.eta * dLb2      \n",
    "        return\n",
    "    # evaluate the total error on the current prediction\n",
    "    def curr_error(self, X, y):\n",
    "        s1 = X.dot(self.W1) + self.b1\n",
    "        a1 = np.tanh(s1)\n",
    "        s2 = a1.dot(self.W2) + self.b2\n",
    "        a2 = np.exp(s2) / np.sum(np.exp(s2), axis=1, keepdims=True)\n",
    "        N = len(X)\n",
    "        error = np.sum(-np.log(a2[range(N), y.astype(int)]))\n",
    "        return 1./N * error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.loadtxt(\"Train_inpX.txt\")\n",
    "y_train=np.loadtxt(\"Train_inpY.txt\")\n",
    "X_test=np.loadtxt(\"Test_inpX.txt\")\n",
    "y_test=np.loadtxt(\"Test_inpY.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN=NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error before the neural network is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.018192614283862"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.curr_error(X_train,y_train)* 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN.gradient_descent(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error after training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.764148845761275"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.curr_error(X_train,y_train)* 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9750218826252031"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.curr_error(X_test,y_test)* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351L, 49L)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
